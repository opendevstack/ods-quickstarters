def final projectId = '@project_id@'
def final componentId = '@component_id@'
def trainingRoute
def trainingPodInfo
def trainingPassword
def trainingUsername
def trainingComponentId = "${componentId}-training-service"
def predictionComponentId = "${componentId}-prediction-service"

@Library('ods-jenkins-shared-library@@ods_git_ref@') _

// See https://www.opendevstack.org/ods-documentation/ods-jenkins-shared-library/latest/index.html for usage and customization.
odsComponentPipeline(
    imageStreamTag: 'cd/jenkins-slave-python:@ods_image_tag@',
    projectId: projectId,
    componentId: componentId,
    testResults : 'tests-results',
    branchToEnvironmentMapping: [
        'master': 'dev',
        // 'release/*': 'test'
    ]
) { context ->
    def buildTimeoutMinutes = 25
    def rolloutTimeoutMinutes = 10

    odsComponentStageScanWithSonar(context)
    stageBuild(context)
    stageLinter(context)
    stageCustomStartOpenshiftBuild(context, "Build Training Image" ,trainingComponentId, buildTimeoutMinutes)
    stageCustomDeployToOpenshift(context, "Deploy Training Pod", trainingComponentId, rolloutTimeoutMinutes)
    stageUnitTestsTraining(context)
    stageTraining(context)
    stageIntegrationTestTraining(context)
    stageCustomStartOpenshiftBuild(context, "Build Prediction Image", predictionComponentId, buildTimeoutMinutes)
    stageCustomDeployToOpenshift(context, "Deploy Prediction Pod", predictionComponentId, rolloutTimeoutMinutes)
}

def stageLinter(def context) {
    stage('Lint') {
        // PEP8
        sh '''
        pycodestyle --show-source --show-pep8 --max-line-length 100 src/model/*
        pycodestyle --statistics -qq --max-line-length 100 src/model/*
        pycodestyle --show-source --show-pep8 --max-line-length 100 src/services/*
        pycodestyle --statistics -qq --max-line-length 100 src/services/*
        pycodestyle --show-source --show-pep8 --max-line-length 100 jenkinsfile_helper.py
        pycodestyle --statistics -qq --max-line-length 100 jenkinsfile_helper.py
        '''
    }
}

def stageBuild(def context) {
    stage('Build') {
        sh 'sh build.sh'
    }
}

def stageUnitTestsTraining(def context) {
    stage('Unit Test') {
        trainingPodInfo = sh(returnStdout: true, script:"oc get pods --sort-by=.status.startTime --no-headers -n ${context.targetProject} | grep ${context.componentId}-training-service | tail -n1").trim().split(/\s+/)
        print("Running Unit Tests in pod ${trainingPodInfo[0]}")
        sh(returnStdout: true, script: "oc exec ${trainingPodInfo[0]} bash ./run_unittests.sh -n ${context.targetProject}")
    }
}

def stageTraining(def context) {
    stage('Train Model') {
        sh(returnStdout: true, script:"pip install -i ${context.nexusHostWithBasicAuth}/repository/pypi-all/simple --trusted-host ${context.nexusHost.tokenize('//')[1]}  requests --user")

        trainingRoute = "http://localhost:8080"

        trainingPassword = sh(returnStdout: true, script:"oc get secret ${context.componentId}-training-secret -o yaml -n ${context.targetProject} | grep password: | cut -d':' -f2 ").trim()
        trainingUsername = sh(returnStdout: true, script:"oc get secret ${context.componentId}-training-secret -o yaml -n ${context.targetProject} | grep username: | cut -d':' -f2 ").trim()
        trainingPassword = sh(returnStdout: true, script:"echo \"${trainingPassword}\" | base64 --decode").trim()
        trainingUsername = sh(returnStdout: true, script:"echo \"${trainingUsername}\" | base64 --decode").trim()

        sh "oc port-forward ${trainingPodInfo[0]} 8080 -n ${context.targetProject} &"
        // wait for port-forward to map the ports or for 10s
        sh "timeout 10s bash -c 'until ! curl -v --silent http://localhost:8080 2>&1 | grep -m 1 \"Connection refused\"; do sleep 1 ; done'; echo -e \\\\a"
        // trigger model training
        sh "python3 jenkinsfile_helper.py --training-service ${trainingRoute} --username \"${trainingUsername}\" --password \"${trainingPassword}\""
        // get the model for the prediction build
        sh "curl -Lv --user \"${trainingUsername}\":\"${trainingPassword}\" \"${trainingRoute}\"/getmodel -o docker/dist/\"${context.getGitCommit()}\""
    }
}

def stageIntegrationTestTraining(def context) {
    stage('Integration Tests') {
        trainingPodInfo = sh(returnStdout: true, script:"oc get pods --sort-by=.status.startTime --no-headers -n ${context.targetProject} | grep ${context.componentId}-training-service | tail -n1").trim().split(/\s+/)
        print("Running Integration Tests in pod ${trainingPodInfo[0]}")
        sh(returnStdout: true, script: "oc -n ${context.targetProject} exec ${trainingPodInfo[0]} bash ./run_integration_tests.sh")
        sh(returnStdout: true, script: "oc -n ${context.targetProject} exec ${trainingPodInfo[0]} cat nosetests.xml > testresults.xml")
        sh "mkdir -p tests-results && mv testresults.xml tests-results/"
    }
}

def stageCustomStartOpenshiftBuild(def context, def stageName, def componentId, def buildTimeoutMinutes) {
    stage(stageName) {
        if (!context.environment) {
            println("Skipping for empty environment ...")
            return
        }
        timeout(buildTimeoutMinutes) {
            patchBuildConfig(context, componentId)
            sh (script: "oc start-build ${componentId} --from-dir docker --follow -n ${context.targetProject}", label : "start openshift build")
        }

        // MRO final stage
        if(componentId.contains('prediction')) {
            def ocpbuildId
            def ocpbuildStatus

            while (ocpbuildStatus == null || ocpbuildStatus.toString().trim().toLowerCase() == "running") {
                def ocpbuild = sh(returnStdout: true, script:"sleep 10 && oc get build --sort-by=.status.startTimestamp -o jsonpath='{.items[-1:].metadata.name},{.items[-1:].status.phase}' -n ${context.targetProject} -l buildconfig=${componentId}", label : "find last build").trim().split(',')
                ocpbuildId = ocpbuild[0]
                ocpbuildStatus = ocpbuild[1]
            }

            if (ocpbuildStatus.toString().trim().toLowerCase() != "complete") {
                error "OCP Build ${ocpbuildId} was not successfull - status ${ocpbuildStatus}"
            }

            def ocpCurrentImage = sh(returnStdout: true, script:"oc get istag ${componentId}:${context.getTagversion()} -n ${context.targetProject} -o jsonpath='{.image.dockerImageReference}'", label : "find new image sha").trim()

            context.addArtifactURI("OCP Build Id", ocpbuildId)
            context.addArtifactURI("OCP Docker image", ocpCurrentImage)
        }
    }
}

private void patchBuildConfig(def context, def componentId) {
    def splitComponentId = componentId.tokenize('-')
    // sanitize commit message
    def sanitizedGitCommitMessage = context.gitCommitMessage.replaceAll("[\r\n]+", " ").trim().replaceAll("[\"']+", "")
    //remove apostrophe in committer name
    def sanitizedGitCommitAuthor = context.gitCommitAuthor.trim().replaceAll("'","")

    // create the default ODS driven labels
    def odsImageLabels = []
    odsImageLabels.push("{\"name\":\"ods.build.source.repo.url\",\"value\":\"${context.gitUrl}\"}")
    odsImageLabels.push("{\"name\":\"ods.build.source.repo.commit.sha\",\"value\":\"${context.gitCommit}\"}")
    odsImageLabels.push("{\"name\":\"ods.build.source.repo.commit.msg\",\"value\":\"${sanitizedGitCommitMessage}\"}")
    odsImageLabels.push("{\"name\":\"ods.build.source.repo.commit.author\",\"value\":\"${sanitizedGitCommitAuthor}\"}")
    odsImageLabels.push("{\"name\":\"ods.build.source.repo.commit.timestamp\",\"value\":\"${context.gitCommitTime}\"}")
    odsImageLabels.push("{\"name\":\"ods.build.source.repo.branch\",\"value\":\"${context.gitBranch}\"}")
    odsImageLabels.push("{\"name\":\"ods.build.jenkins.job.url\",\"value\":\"${context.buildUrl}\"}")
    odsImageLabels.push("{\"name\":\"ods.build.timestamp\",\"value\":\"${context.buildTime}\"}")
    odsImageLabels.push("{\"name\":\"ods.build.lib.version\",\"value\":\"${context.odsSharedLibVersion}\"}")

    // write the file - so people can pick it up in the Dockerfile
    writeFile file: 'docker/release.json', text: "[" + odsImageLabels.join(",") + "]"

    // Normally we want to replace the imageLabels, but in case they are not
    // present yet, we need to add them this time.
    def imageLabelsOp = "replace"
    def imageLabelsValue = sh(
        script: "oc -n ${context.targetProject} get bc/${componentId} -o jsonpath='{.spec.output.imageLabels}'",
        returnStdout: true,
        label: "Test existance of path .spec.output.imageLabels"
    ).trim()
    if (imageLabelsValue.length() == 0) {
        imageLabelsOp = "add"
    }

    def patches = [
        '{"op": "replace", "path": "/spec/source", "value": {"type":"Binary"}}',
        """{"op": "replace", "path": "/spec/output/to/name", "value": "${componentId}:${context.tagversion}"}""",
        """{"op": "${imageLabelsOp}", "path": "/spec/output/imageLabels", "value": [
            ${odsImageLabels.join(",")}
        ]}""",
        """{"op": "replace", "path": "/spec/strategy/dockerStrategy",
            "value":{"buildArgs":[
                {"name": "nexusHostWithBasicAuth" ,"value": "${context.nexusHostWithBasicAuth}"},
                {"name": "nexusHostWithoutScheme" ,"value": "${context.nexusHost.tokenize('//')[1]}"},
                {"name": "serviceType" ,"value": "${splitComponentId[ splitComponentId.size() - 2 ]}"}
        ]}}"""
    ]

    sh """oc patch bc ${componentId} --type=json --patch '[${patches.join(",")}]' -n ${context.targetProject}"""
}

def stageCustomDeployToOpenshift(def context, def stageName, def componentId, def rolloutTimeoutMinutes) {
    stage(stageName) {
        if (!context.environment) {
            echo "Skipping for empty environment ..."
            return
        }

        def deploymentConfigExists = utilsOpenshift.deploymentConfigExists(
            context,
            context.targetProject,
            componentId
        )
        if (!deploymentConfigExists) {
            error "No DeploymentConfig ${componentId} found in ${context.targetProject}."
        }
        def imageStreamExists = utilsOpenshift.imageStreamExists(
            context,
            context.targetProject,
            componentId
        )
        if (!imageStreamExists) {
            error "No ImageStream ${componentId} found in ${context.targetProject}."
        }

        def imageTriggerEnabled = utilsOpenshift.automaticImageChangeTriggerEnabled(
            context,
            context.targetProject,
            componentId
        )

        utilsOpenshift.setLatestImageTag(
            context,
            context.targetProject,
            componentId,
            context.tagversion
        )

        def deployment = utilsOpenshift.rolloutDeployment(
            context,
            context.targetProject,
            componentId,
            rolloutTimeoutMinutes,
            !imageTriggerEnabled
        )

        waitForTrainingPod(context, componentId)

        // MRO final stage
        if(componentId.contains('prediction')) {
            if (deployment == null) {
                error "Deployment failed, please check the error in the OCP console."
            } else if (deployment.status.toLowerCase() != "complete") {
                error "Deployment ${deployment.id} failed with status '${deployment.status}', please check the error in the OCP console."
            } else {
                echo "Deployment ${deployment.id} successfully rolled out."
                context.addArtifactURI("OCP Deployment Id", deployment.id)
            }
        }
    }
}

def waitForTrainingPod(def context, def componentId) {
    if(componentId.contains('training')) {
        print("Start waiting for training pod to be running...")
        while(true) {
            trainingPodInfo = sh(returnStdout: true, script:"sleep 5 && oc get pods --sort-by=.status.startTime --no-headers -n ${context.targetProject} | grep ${componentId} | grep -v deploy | tail -n1").trim().split(/\s+/)
            print("Waiting for training pod ${trainingPodInfo[0]} to be running...")
            if (trainingPodInfo[2] == "Running") {
                print("Pod ${trainingPodInfo[0]} is running!!!")
                break
            }
            print("Pod ${trainingPodInfo[0]} is still not running...")
        }
    }
}
